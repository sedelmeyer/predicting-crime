{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 000: Download Datasources\n",
    "\n",
    "The code in this notebook can be used to download a large portion of the `raw` data sources required for the \"Predicting Crimes\" analysis.\n",
    "\n",
    "If you wish bypass using this code, and would like to simply download a copy of the fully populated `raw` data directory, you can do so by:\n",
    "\n",
    "1. Downloading and extracting the `./raw/` data directory found at this link:\n",
    "    - https://drive.google.com/file/d/1Pv5M-GmUY2Cvq92GDH3d_h7MvXFjgzID/view?usp=sharing\n",
    "\n",
    "\n",
    "2. Replacing your local \"raw\" data sub-directory found at `../data/raw/` in this project repository.\n",
    "3. Please DO NOT commit any data files to your git history. \n",
    "\n",
    "**PLEASE NOTE:** Not included in the code below are data sources requiring API calls nor are data sources requiring web-scraping activities. Those data sources will be pulled using separate notebooks *(NOT YET COMPLETED)*.\n",
    "\n",
    "**Overall, 44 separate data and shape files listed in the accompanying `data-inventory.csv` file are downloaded by this notebook.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "import requests\n",
    "import zipfile\n",
    "from pathlib import PurePath\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path variables\n",
    "DATA_ROOT = '../data'\n",
    "parent_dir = os.path.join(DATA_ROOT, 'raw')\n",
    "inventory_filepath = os.path.join('../data-inventory.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data inventory to dataframe\n",
    "inventory_df = pd.read_csv(inventory_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 47 entries, 0 to 46\n",
      "Data columns (total 13 columns):\n",
      "id                  47 non-null int64\n",
      "category            47 non-null object\n",
      "access              47 non-null object\n",
      "source              45 non-null object\n",
      "directory           47 non-null object\n",
      "sub-directory       47 non-null object\n",
      "filename            45 non-null object\n",
      "zipfile             37 non-null float64\n",
      "page-url            47 non-null object\n",
      "data-url            45 non-null object\n",
      "reference           33 non-null object\n",
      "description         44 non-null object\n",
      "access-confirmed    44 non-null object\n",
      "dtypes: float64(1), int64(1), object(11)\n",
      "memory usage: 4.9+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "      <th>access</th>\n",
       "      <th>source</th>\n",
       "      <th>directory</th>\n",
       "      <th>sub-directory</th>\n",
       "      <th>filename</th>\n",
       "      <th>zipfile</th>\n",
       "      <th>page-url</th>\n",
       "      <th>data-url</th>\n",
       "      <th>reference</th>\n",
       "      <th>description</th>\n",
       "      <th>access-confirmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>boston property assessments</td>\n",
       "      <td>download</td>\n",
       "      <td>data</td>\n",
       "      <td>raw</td>\n",
       "      <td>property</td>\n",
       "      <td>fy19-assessments</td>\n",
       "      <td>0.0</td>\n",
       "      <td>https://data.boston.gov/dataset/property-asses...</td>\n",
       "      <td>https://data.boston.gov/dataset/e02c44d2-3c64-...</td>\n",
       "      <td>, https://data.boston.gov/dataset/e02c44d2-3c6...</td>\n",
       "      <td>Gives property, or parcel, ownership together ...</td>\n",
       "      <td>2019-11-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                     category    access source directory sub-directory  \\\n",
       "0   1  boston property assessments  download   data       raw      property   \n",
       "\n",
       "           filename  zipfile  \\\n",
       "0  fy19-assessments      0.0   \n",
       "\n",
       "                                            page-url  \\\n",
       "0  https://data.boston.gov/dataset/property-asses...   \n",
       "\n",
       "                                            data-url  \\\n",
       "0  https://data.boston.gov/dataset/e02c44d2-3c64-...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  , https://data.boston.gov/dataset/e02c44d2-3c6...   \n",
       "\n",
       "                                         description access-confirmed  \n",
       "0  Gives property, or parcel, ownership together ...       2019-11-07  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view summary of data inventory\n",
    "print(inventory_df.info())\n",
    "inventory_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions for performing data downloads\n",
    "def make_subdir(subdir, verbose=True):\n",
    "    \"\"\"\n",
    "    Checks for the existance of a specified sub-directory, and if it\n",
    "    doesn't exist, the sub-directory is created\n",
    "    \n",
    "    subdir: str, relative filepath of the desired subdirectory\n",
    "    verbose: boolean, default=True, if True prints summary of action taken\n",
    "    \n",
    "    returns: None, sub-directory written to disk at specified filepath\n",
    "    \"\"\"\n",
    "    if os.path.exists(subdir):\n",
    "        if verbose:\n",
    "            print(\n",
    "                'The following sub-directory already exists '\\\n",
    "                'and was not created: {0}'.format(subdir)\n",
    "            )\n",
    "    \n",
    "    else:\n",
    "        os.mkdir(subdir)\n",
    "        if verbose:\n",
    "            print(\n",
    "                'The following sub-directory was created: {0}'\\\n",
    "                ''.format(subdir)\n",
    "            )\n",
    "\n",
    "\n",
    "def download_file(subdir, url, filename, verbose=True,\n",
    "                  overwrite=False, return_results=True):\n",
    "    \"\"\"\n",
    "    Downloads a single file to the specified filepath from the given url\n",
    "    \n",
    "    subdir: str, the path of target directory for saving file\n",
    "    url: str, the url from which the data will be downloaded\n",
    "    filename: str, the desired name of the saved file\n",
    "    verbose: boolean, default=True, if True prints summary of action taken\n",
    "    overwrite: boolean, default=False, if True will overwrite existing local\n",
    "               copy of the file, if False will only download file if it's\n",
    "               filepath does not already exists\n",
    "    return_results: boolean, default=True, if True returns new local filename\n",
    "                    and download headers\n",
    "               \n",
    "    returns: if return_results=True, returns local_filename and headers from\n",
    "             urllib.request.urlretrieve, or if local file already existed\n",
    "             and overwrite=False returns nothing\n",
    "    \"\"\"\n",
    "    filepath = os.path.join(subdir, filename)\n",
    "    \n",
    "    # check for existence of subdir and mkdir if needed\n",
    "    make_subdir(subdir, verbose=verbose)\n",
    "    \n",
    "    # overwrite existing file if it exists\n",
    "    if overwrite:\n",
    "        if os.path.exists(filepath):\n",
    "            if verbose:\n",
    "                print(\n",
    "                    'Downloading and overwritting the existing '\\\n",
    "                    'local file: {0}'.format(filepath)\n",
    "                )\n",
    "            local_filename, headers = urllib.request.urlretrieve(\n",
    "                url,\n",
    "                filepath,\n",
    "            )\n",
    "            if return_results:\n",
    "                return local_filename, headers\n",
    "    \n",
    "    # write file to disk if it does not already exist\n",
    "    if not os.path.exists(filepath):\n",
    "        if verbose:\n",
    "            print(\n",
    "                'Downloading {0} data to {1}'.format(subdir, filepath)\n",
    "            )                \n",
    "        local_filename, headers = urllib.request.urlretrieve(\n",
    "            url,\n",
    "            filepath,\n",
    "        )\n",
    "        if return_results:\n",
    "            return local_filename, headers\n",
    "    \n",
    "    # handle situation where filepath exists and will not be overwritten\n",
    "    if not overwrite:\n",
    "        if os.path.exists(filepath):\n",
    "            if verbose:\n",
    "                print(\n",
    "                    'The following local file already exists and '\\\n",
    "                    'was not overwritten: {0}'.format(filepath)\n",
    "                )\n",
    "            if return_results:\n",
    "                return None, None\n",
    "\n",
    "\n",
    "def make_download_dict(inventory, parent):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    subdirs = list(set(inventory['sub-directory']))\n",
    "    inventory['file-type'] = download_df['data-url'].apply(\n",
    "        lambda x: os.path.join(*PurePath(x).suffixes)\n",
    "    )\n",
    "    \n",
    "    download_dict = {\n",
    "        subdir: {\n",
    "            filename: {\n",
    "                'url': url,\n",
    "                'filepath': os.path.join(parent, subdir, ''.join([filename, suffix])),\n",
    "                'is_zip': is_zip\n",
    "            }\n",
    "            for filename, url, suffix, is_zip in zip(\n",
    "                inventory.loc[inventory_df['sub-directory'] == subdir]['filename'],\n",
    "                inventory.loc[inventory_df['sub-directory'] == subdir]['data-url'],\n",
    "                inventory.loc[inventory_df['sub-directory'] == subdir]['file-type'],\n",
    "                inventory.loc[inventory_df['sub-directory'] == subdir]['zipfile'],\n",
    "            )\n",
    "        } for subdir in subdirs\n",
    "    }\n",
    "    \n",
    "    return download_dict\n",
    "\n",
    "\n",
    "def make_subdirs(download_dict, parent, verbose=True):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    if not os.path.exists(parent):\n",
    "        os.mkdir(parent)\n",
    "        open(os.path.join(parent, '.gitkeep'), 'a').close()\n",
    "        if verbose:\n",
    "            print(\n",
    "                'The {0} parent directory and accompanying .gitkeep file '\\\n",
    "                'have been created.'.format(parent)\n",
    "            )\n",
    "            print()\n",
    "    \n",
    "    # create list of current top-level files and directories\n",
    "    existing = os.listdir(parent)\n",
    "\n",
    "    # check for ./data/ dir and create if it doesn't exist\n",
    "    [\n",
    "        os.mkdir(os.path.join(parent, subdir))\n",
    "        for subdir in download_dict.keys() if not subdir in existing \n",
    "    ]\n",
    "    \n",
    "    # save new list of files and directories, as well is difference\n",
    "    new_existing = os.listdir(parent)\n",
    "    new_added = list(set(new_existing) - set(existing))\n",
    "    \n",
    "    # print summary results\n",
    "    if verbose:\n",
    "        if len(new_added) > 0:\n",
    "            print('The following sub-directories were added to {}:'.format(parent))\n",
    "            for subdir in new_added:\n",
    "                print(subdir)\n",
    "            print()\n",
    "        else:\n",
    "            print(\n",
    "                'No directories have been created. All target directories already '\\\n",
    "                'exist locally\\n'\n",
    "            )\n",
    "    \n",
    "    return new_existing, new_added\n",
    "\n",
    "\n",
    "def download_datafiles(download_dict, parent, exclude_subdir='shapefile', verbose=True):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    subdirs = [\n",
    "        subdir for subdir in list(download_dict.keys())\n",
    "        if subdir not in exclude_subdir\n",
    "    ]\n",
    "    downloaded = dict()\n",
    "    \n",
    "    for subdir in subdirs:\n",
    "        for filename, download in download_dict[subdir].items():\n",
    "            if not os.path.exists(download['filepath']):\n",
    "                if verbose:\n",
    "                    print(\n",
    "                        'Downloading {0} data to {1}'.format(filename, download['filepath'])\n",
    "                    )                \n",
    "                downloaded[filename] = [\n",
    "                    urllib.request.urlretrieve(\n",
    "                        download['url'],\n",
    "                        download['filepath'],\n",
    "                    )\n",
    "                ]\n",
    "    \n",
    "    if verbose:\n",
    "        if len(downloaded)==0:\n",
    "            print(\n",
    "                'No datafiles have been downloaded. All target files already exist locally.\\n'\n",
    "            )\n",
    "        else:\n",
    "            print(\n",
    "                '{0} data files have been downloaded and stored locally.\\n'.format(\n",
    "                    len(downloaded)\n",
    "                )\n",
    "            )\n",
    "    \n",
    "    return downloaded\n",
    "\n",
    "\n",
    "def download_shapefiles(download_dict, parent, target_subdir='shapefile', verbose=True):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    downloaded = dict()\n",
    "    \n",
    "    for filename, download in download_dict[target_subdir].items():\n",
    "        if not os.path.exists(download['filepath']):\n",
    "            if verbose:\n",
    "                print(\n",
    "                    'Downloading {0} shapefile to {1}'.format(filename, download['filepath'])\n",
    "                )                \n",
    "            \n",
    "            # download shape zipfile to directory\n",
    "            downloaded[filename] = [\n",
    "                urllib.request.urlretrieve(\n",
    "                    download['url'],\n",
    "                    download['filepath'],\n",
    "                )\n",
    "            ]\n",
    "            \n",
    "            # create target sub-directory for extracting zipfile\n",
    "            shapedir = os.path.join(os.path.dirname(download['filepath']), filename)\n",
    "            if not os.path.exists(shapedir):\n",
    "                os.mkdir(shapedir)\n",
    "            \n",
    "            # extract zipfile to target sub-directory\n",
    "            with zipfile.ZipFile(download['filepath'], 'r') as zipobj:\n",
    "\n",
    "                if verbose:\n",
    "                    print(\n",
    "                        '\\t...extracting shapefile zip archive to {0}'.format(shapedir)\n",
    "                    )                \n",
    "\n",
    "                # extract all files\n",
    "                zipobj.extractall(shapedir)\n",
    "\n",
    "    if verbose:\n",
    "        if len(downloaded)==0:\n",
    "            print(\n",
    "                'No shapefiles have been downloaded. All target files already exist locally.\\n'\n",
    "            )\n",
    "        else:\n",
    "            print(\n",
    "                '{0} shapefiles have been downloaded and extracted locally.\\n'.format(\n",
    "                    len(downloaded)\n",
    "                )\n",
    "            )\n",
    "            \n",
    "    return downloaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset data inventory into groups based on required download methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset data inventory to separate include just 'downloads'\n",
    "cols = ['sub-directory', 'filename', 'zipfile', 'data-url', 'source']\n",
    "download_df = inventory_df.loc[inventory_df['access']=='download'][cols]\n",
    "\n",
    "# subset NOAA API query download information\n",
    "noaa_df = inventory_df.loc[inventory_df['sub-directory']=='noaa'][cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download NOAA weather data with direct API url query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following sub-directory already exists and was not created: ../data/raw/noaa\n",
      "The following local file already exists and was not overwritten: ../data/raw/noaa/boston-daily-weather-20140101-20191107.csv\n"
     ]
    }
   ],
   "source": [
    "noaa_results = download_file(\n",
    "    subdir=os.path.join(parent_dir, 'noaa'),\n",
    "    url=noaa_df['data-url'].values[0],\n",
    "    filename=noaa_df['filename'].values[0],\n",
    "    return_results=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download files from Boston Analyze data sources\n",
    "\n",
    "This includes both \"data\" sources such as .csv and .xlsx files as well as \"shapefile\" .zip sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ../data/raw parent directory and accompanying .gitkeep file has been created.\n",
      "\n",
      "The following sub-directories were added to ../data/raw:\n",
      "crime\n",
      "property\n",
      "bpd-fio\n",
      "boston\n",
      "shapefile\n",
      "\n",
      "Downloading crime-incidents data to ../data/raw/crime/crime-incidents.csv\n",
      "Downloading fy19-assessments data to ../data/raw/property/fy19-assessments.csv\n",
      "Downloading fy18-assessments data to ../data/raw/property/fy18-assessments.csv\n",
      "Downloading fy17-assessments data to ../data/raw/property/fy17-assessments.csv\n",
      "Downloading fy16-assessments data to ../data/raw/property/fy16-assessments.csv\n",
      "Downloading fy15-assessments data to ../data/raw/property/fy15-assessments.csv\n",
      "Downloading fy14-assessments data to ../data/raw/property/fy14-assessments.csv\n",
      "Downloading fy13-assessments data to ../data/raw/property/fy13-assessments.csv\n",
      "Downloading streetlights data to ../data/raw/boston/streetlights.csv\n",
      "Downloading public-k12-schools data to ../data/raw/boston/public-k12-schools.csv\n",
      "Downloading nonpublic-k12-schools data to ../data/raw/boston/nonpublic-k12-schools.csv\n",
      "Downloading colleges-universities data to ../data/raw/boston/colleges-universities.csv\n",
      "Downloading fire-depts data to ../data/raw/boston/fire-depts.csv\n",
      "Downloading police-stations data to ../data/raw/boston/police-stations.csv\n",
      "Downloading sam-addresses data to ../data/raw/boston/sam-addresses.csv\n",
      "Downloading income-restricted-housing data to ../data/raw/boston/income-restricted-housing.csv\n",
      "Downloading liquor-licenses data to ../data/raw/boston/liquor-licenses.csv\n",
      "Downloading publicworks-violations data to ../data/raw/boston/publicworks-violations.csv\n",
      "Downloading property-violations data to ../data/raw/boston/property-violations.csv\n",
      "Downloading food-inspections data to ../data/raw/boston/food-inspections.csv\n",
      "Downloading building-permits data to ../data/raw/boston/building-permits.csv\n",
      "Downloading neighborhood-demographics-1950-2010 data to ../data/raw/boston/neighborhood-demographics-1950-2010.xlsx\n",
      "Downloading neighborhood-demographics-2013-2017-acs data to ../data/raw/boston/neighborhood-demographics-2013-2017-acs.xlsx\n",
      "Downloading blc-landmarks data to ../data/raw/boston/blc-landmarks.csv\n",
      "Downloading community-centers data to ../data/raw/boston/community-centers.csv\n",
      "Downloading public-trees data to ../data/raw/boston/public-trees.csv\n",
      "Downloading bpd-fio-records-2016 data to ../data/raw/bpd-fio/bpd-fio-records-2016.csv\n",
      "Downloading bpd-fio-records-2016-name-table data to ../data/raw/bpd-fio/bpd-fio-records-2016-name-table.csv\n",
      "Downloading bpd-fio-records-2015 data to ../data/raw/bpd-fio/bpd-fio-records-2015.csv\n",
      "Downloading bpd-fio-records-2015-name-table data to ../data/raw/bpd-fio/bpd-fio-records-2015-name-table.csv\n",
      "Downloading bpd-fio-records-2011-2015 data to ../data/raw/bpd-fio/bpd-fio-records-2011-2015.csv\n",
      "31 data files have been downloaded and stored locally.\n",
      "\n",
      "Downloading open-spaces shapefile to ../data/raw/shapefile/open-spaces.zip\n",
      "\t...extracting shapefile zip archive to ../data/raw/shapefile/open-spaces\n",
      "Downloading zipcodes shapefile to ../data/raw/shapefile/zipcodes.zip\n",
      "\t...extracting shapefile zip archive to ../data/raw/shapefile/zipcodes\n",
      "Downloading boston-neighborhoods shapefile to ../data/raw/shapefile/boston-neighborhoods.zip\n",
      "\t...extracting shapefile zip archive to ../data/raw/shapefile/boston-neighborhoods\n",
      "Downloading sidewalk-centerlines shapefile to ../data/raw/shapefile/sidewalk-centerlines.zip\n",
      "\t...extracting shapefile zip archive to ../data/raw/shapefile/sidewalk-centerlines\n",
      "Downloading planning-districts shapefile to ../data/raw/shapefile/planning-districts.zip\n",
      "\t...extracting shapefile zip archive to ../data/raw/shapefile/planning-districts\n",
      "Downloading water-features shapefile to ../data/raw/shapefile/water-features.zip\n",
      "\t...extracting shapefile zip archive to ../data/raw/shapefile/water-features\n",
      "Downloading zoning-districts shapefile to ../data/raw/shapefile/zoning-districts.zip\n",
      "\t...extracting shapefile zip archive to ../data/raw/shapefile/zoning-districts\n",
      "Downloading zoning-subdistricts shapefile to ../data/raw/shapefile/zoning-subdistricts.zip\n",
      "\t...extracting shapefile zip archive to ../data/raw/shapefile/zoning-subdistricts\n",
      "Downloading sidewalk-inventory shapefile to ../data/raw/shapefile/sidewalk-inventory.zip\n",
      "\t...extracting shapefile zip archive to ../data/raw/shapefile/sidewalk-inventory\n",
      "Downloading main-street-districts shapefile to ../data/raw/shapefile/main-street-districts.zip\n",
      "\t...extracting shapefile zip archive to ../data/raw/shapefile/main-street-districts\n",
      "Downloading city-boundary shapefile to ../data/raw/shapefile/city-boundary.zip\n",
      "\t...extracting shapefile zip archive to ../data/raw/shapefile/city-boundary\n",
      "Downloading census-tracts shapefile to ../data/raw/shapefile/census-tracts.zip\n",
      "\t...extracting shapefile zip archive to ../data/raw/shapefile/census-tracts\n",
      "Downloading street-segments shapefile to ../data/raw/shapefile/street-segments.zip\n",
      "\t...extracting shapefile zip archive to ../data/raw/shapefile/street-segments\n",
      "13 shapefiles have been downloaded and extracted locally.\n",
      "\n",
      "CPU times: user 17.3 s, sys: 8.64 s, total: 26 s\n",
      "Wall time: 5min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# report cell execution time for later reference\n",
    "\n",
    "# create download dictionary\n",
    "download_dict = make_download_dict(download_df, parent_dir)\n",
    "\n",
    "# make required sub-directories in parent directory\n",
    "listdirs, added = make_subdirs(download_dict, parent_dir)\n",
    "\n",
    "# download data files to target sub-directories\n",
    "downloaded_data_confirmation = download_datafiles(download_dict, parent_dir)\n",
    "\n",
    "# download and extract shapefiles to target sub-directories\n",
    "downloaded_shape_confirmation = download_shapefiles(download_dict, parent_dir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
