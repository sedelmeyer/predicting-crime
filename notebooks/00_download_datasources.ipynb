{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "import requests\n",
    "import zipfile\n",
    "from pathlib import PurePath\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path variables\n",
    "DATA_ROOT = '../data'\n",
    "parent_dir = os.path.join(DATA_ROOT, 'raw')\n",
    "inventory_filepath = os.path.join(DATA_ROOT, 'data-inventory.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data inventory to dataframe\n",
    "inventory_df = pd.read_csv(inventory_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 47 entries, 0 to 46\n",
      "Data columns (total 13 columns):\n",
      "id                  47 non-null int64\n",
      "category            47 non-null object\n",
      "access              47 non-null object\n",
      "source              44 non-null object\n",
      "directory           47 non-null object\n",
      "sub-directory       47 non-null object\n",
      "filename            44 non-null object\n",
      "zipfile             37 non-null float64\n",
      "page-url            47 non-null object\n",
      "data-url            44 non-null object\n",
      "reference           32 non-null object\n",
      "description         44 non-null object\n",
      "access-confirmed    44 non-null object\n",
      "dtypes: float64(1), int64(1), object(11)\n",
      "memory usage: 4.9+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "      <th>access</th>\n",
       "      <th>source</th>\n",
       "      <th>directory</th>\n",
       "      <th>sub-directory</th>\n",
       "      <th>filename</th>\n",
       "      <th>zipfile</th>\n",
       "      <th>page-url</th>\n",
       "      <th>data-url</th>\n",
       "      <th>reference</th>\n",
       "      <th>description</th>\n",
       "      <th>access-confirmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>boston property assessments</td>\n",
       "      <td>download</td>\n",
       "      <td>data</td>\n",
       "      <td>raw</td>\n",
       "      <td>property</td>\n",
       "      <td>fy19-assessments</td>\n",
       "      <td>0.0</td>\n",
       "      <td>https://data.boston.gov/dataset/property-asses...</td>\n",
       "      <td>https://data.boston.gov/dataset/e02c44d2-3c64-...</td>\n",
       "      <td>, https://data.boston.gov/dataset/e02c44d2-3c6...</td>\n",
       "      <td>Gives property, or parcel, ownership together ...</td>\n",
       "      <td>2019-11-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                     category    access source directory sub-directory  \\\n",
       "0   1  boston property assessments  download   data       raw      property   \n",
       "\n",
       "           filename  zipfile  \\\n",
       "0  fy19-assessments      0.0   \n",
       "\n",
       "                                            page-url  \\\n",
       "0  https://data.boston.gov/dataset/property-asses...   \n",
       "\n",
       "                                            data-url  \\\n",
       "0  https://data.boston.gov/dataset/e02c44d2-3c64-...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  , https://data.boston.gov/dataset/e02c44d2-3c6...   \n",
       "\n",
       "                                         description access-confirmed  \n",
       "0  Gives property, or parcel, ownership together ...       2019-11-07  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view summary of data inventory\n",
    "print(inventory_df.info())\n",
    "inventory_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset data inventory to include just 'downloads'\n",
    "cols = ['sub-directory', 'filename', 'zipfile', 'data-url', 'source']\n",
    "download_df = inventory_df.loc[inventory_df['access']=='download'][cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions for performing data downloads\n",
    "\n",
    "def make_download_dict(inventory, parent):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    subdirs = list(set(inventory['sub-directory']))\n",
    "    inventory['file-type'] = download_df['data-url'].apply(\n",
    "        lambda x: os.path.join(*PurePath(x).suffixes)\n",
    "    )\n",
    "    \n",
    "    download_dict = {\n",
    "        subdir: {\n",
    "            filename: {\n",
    "                'url': url,\n",
    "                'filepath': os.path.join(parent, subdir, ''.join([filename, suffix])),\n",
    "                'is_zip': is_zip\n",
    "            }\n",
    "            for filename, url, suffix, is_zip in zip(\n",
    "                inventory.loc[inventory_df['sub-directory'] == subdir]['filename'],\n",
    "                inventory.loc[inventory_df['sub-directory'] == subdir]['data-url'],\n",
    "                inventory.loc[inventory_df['sub-directory'] == subdir]['file-type'],\n",
    "                inventory.loc[inventory_df['sub-directory'] == subdir]['zipfile'],\n",
    "            )\n",
    "        } for subdir in subdirs\n",
    "    }\n",
    "    \n",
    "    return download_dict\n",
    "\n",
    "\n",
    "def make_subdirs(download_dict, parent, verbose=True):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    if not os.path.exists(parent):\n",
    "        os.mkdir(parent)\n",
    "        open('.gitkeep', 'a').close()\n",
    "        if verbose:\n",
    "            print('The {0} parent directory has been created.'.format(parent))\n",
    "            print()\n",
    "    \n",
    "    # create list of current top-level files and directories\n",
    "    existing = os.listdir(parent)\n",
    "\n",
    "    # check for ./data/ dir and create if it doesn't exist\n",
    "    [\n",
    "        os.mkdir(os.path.join(parent, subdir))\n",
    "        for subdir in download_dict.keys() if not subdir in existing \n",
    "    ]\n",
    "    \n",
    "    # save new list of files and directories, as well is difference\n",
    "    new_existing = os.listdir(parent)\n",
    "    new_added = list(set(new_existing) - set(existing))\n",
    "    \n",
    "    # print summary results\n",
    "    if verbose:\n",
    "        if len(new_added) > 0:\n",
    "            print('The following sub-directories were added to {}:'.format(parent))\n",
    "            for subdir in new_added:\n",
    "                print(subdir)\n",
    "            print()\n",
    "        else:\n",
    "            print(\n",
    "                'No directories have been created. All target directories already '\\\n",
    "                'exist locally\\n'\n",
    "            )\n",
    "    \n",
    "    return new_existing, new_added\n",
    "\n",
    "\n",
    "def download_datafiles(download_dict, parent, exclude_subdir='shapefile', verbose=True):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    subdirs = [\n",
    "        subdir for subdir in list(download_dict.keys())\n",
    "        if subdir not in exclude_subdir\n",
    "    ]\n",
    "    downloaded = dict()\n",
    "    \n",
    "    for subdir in subdirs:\n",
    "        for filename, download in download_dict[subdir].items():\n",
    "            if not os.path.exists(download['filepath']):\n",
    "                if verbose:\n",
    "                    print(\n",
    "                        'Downloading {0} data to {1}'.format(filename, download['filepath'])\n",
    "                    )                \n",
    "                downloaded[filename] = [\n",
    "                    urllib.request.urlretrieve(\n",
    "                        download['url'],\n",
    "                        download['filepath'],\n",
    "                    )\n",
    "                ]\n",
    "    \n",
    "    if verbose:\n",
    "        if len(downloaded)==0:\n",
    "            print(\n",
    "                'No datafiles have been downloaded. All target files already exist locally.\\n'\n",
    "            )\n",
    "        else:\n",
    "            print(\n",
    "                '{0} data files have been downloaded and stored locally.\\n'.format(\n",
    "                    len(downloaded)\n",
    "                )\n",
    "            )\n",
    "    \n",
    "    return downloaded\n",
    "\n",
    "\n",
    "def download_shapefiles(download_dict, parent, target_subdir='shapefile', verbose=True):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    downloaded = dict()\n",
    "    \n",
    "    for filename, download in download_dict[target_subdir].items():\n",
    "        if not os.path.exists(download['filepath']):\n",
    "            if verbose:\n",
    "                print(\n",
    "                    'Downloading {0} shapefile to {1}'.format(filename, download['filepath'])\n",
    "                )                \n",
    "            \n",
    "            # download shape zipfile to directory\n",
    "            downloaded[filename] = [\n",
    "                urllib.request.urlretrieve(\n",
    "                    download['url'],\n",
    "                    download['filepath'],\n",
    "                )\n",
    "            ]\n",
    "            \n",
    "            # create target sub-directory for extracting zipfile\n",
    "            shapedir = os.path.join(os.path.dirname(download['filepath']), filename)\n",
    "            if not os.path.exists(shapedir):\n",
    "                os.mkdir(shapedir)\n",
    "            \n",
    "            # extract zipfile to target sub-directory\n",
    "            with zipfile.ZipFile(download['filepath'], 'r') as zipobj:\n",
    "\n",
    "                if verbose:\n",
    "                    print(\n",
    "                        '\\t...extracting shapefile zip archive to {0}'.format(shapedir)\n",
    "                    )                \n",
    "\n",
    "                # extract all files\n",
    "                zipobj.extractall(shapedir)\n",
    "\n",
    "    if verbose:\n",
    "        if len(downloaded)==0:\n",
    "            print(\n",
    "                'No shapefiles have been downloaded. All target files already exist locally.\\n'\n",
    "            )\n",
    "        else:\n",
    "            print(\n",
    "                '{0} shapefiles have been downloaded and extracted locally.\\n'.format(\n",
    "                    len(downloaded)\n",
    "                )\n",
    "            )\n",
    "            \n",
    "    return downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_dict = make_download_dict(download_df, parent_dir)\n",
    "\n",
    "# make required parent and sub-directories\n",
    "listdirs, added = make_subdirs(download_dict, parent_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No directories have been created. All target directories already exist locally\n",
      "\n",
      "No datafiles have been downloaded. All target files already exist locally.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# report cell execution time for later reference\n",
    "\n",
    "# create download dictionary\n",
    "download_dict = make_download_dict(download_df, parent_dir)\n",
    "\n",
    "# make required sub-directories in parent directory\n",
    "listdirs, added = make_subdirs(download_dict, parent_dir)\n",
    "\n",
    "# download data files to target sub-directories\n",
    "downloaded_data_confirmation = download_datafiles(download_dict, parent_dir)\n",
    "\n",
    "# download and extract shapefiles to target sub-directories\n",
    "downloaded_shape_confirmation = download_shapefiles(download_dict, parent_dir) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
